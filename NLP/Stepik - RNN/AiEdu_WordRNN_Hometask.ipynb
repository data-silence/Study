{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scyE4k8gpwl0"
      },
      "source": [
        "# Домашнее задание: BiLSTM для задачи PoS Tagging\n",
        "\n",
        "В этом ноутбуке мы будем создавать модель машинного обучения, которая генерирует результат для каждого элемента входной последовательности с использованием PyTorch и TorchText. Конкретно, мы будем подавать текст на вход, а модель будет выводить метку - часть речи (PoS) для каждого токена во входном тексте. Этот подход также может применяться для распознавания именованных сущностей (NER), где результатом для каждого токена будет указание на тип сущности, если таковая имеется.\n",
        "\n",
        "В этом блокноте мы реализуем многослойную двунаправленную LSTM (BiLSTM) для предсказания меток частей речи с использованием набора данных Universal Dependencies English Web Treebank (UDPOS)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "id": "5Xf-0XQQW9G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9osUMmompwl2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5OZxOjBpwl3"
      },
      "source": [
        "Зафиксируем случайности для воспроизводимости результатов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egSkC0DDpwl4"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTuoKelVpwl4"
      },
      "source": [
        "В этом наборе данных есть два разных набора меток: метки универсальных зависимостей (UD) и метки Penn Treebank (PTB). Мы будем обучать модель только на метках UD, но загрузим метки PTB, чтобы показать, как их можно использовать вместо них.\n",
        "\n",
        "* UD_TAGS определяет, как следует обрабатывать метки UD. В нашем словаре TEXT, который мы создадим позже, будут неизвестные токены, то есть токены, которых нет в нашем словаре. Однако у нас не будет неизвестных меток, поскольку мы имеем дело с конечным набором возможных меток. Мы будем обозначать неизвестные токены как <unk>, и затем будем их убирать, установив unk_token = None.\n",
        "\n",
        "* PTB_TAGS выполняет то же самое, что и UD_TAGS, но обрабатывает метки PTB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fidoBBJfpwl5"
      },
      "source": [
        "from torchtext.data import Field\n",
        "\n",
        "TEXT = Field(lower = True)\n",
        "UD_TAGS = Field(unk_token = None)\n",
        "PTB_TAGS = Field(unk_token = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqya4Ki-pwl6"
      },
      "source": [
        "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AHzDh46pwl7"
      },
      "source": [
        "Загрузим датасет UDPOS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_RLyzzpwl7"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cHlSTlEpwl7"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Посмотрите на количество объектов в датасетах `train_data, valid_data и test_data`. В ответ запишите число объектов в самом маленьком датасете."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCznT-c3pwl8"
      },
      "source": [
        "# ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIY61Z5Cpwl9"
      },
      "source": [
        "Напечатаем пример из датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpadMDOCpwl9"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39xsVtxpwl9"
      },
      "source": [
        "Можем отдельно посмотреть на текст и на теги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UULauMEBpwl-"
      },
      "source": [
        "print(vars(train_data.examples[0])['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACWgCsPqpwl-"
      },
      "source": [
        "print(vars(train_data.examples[0])['udtags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko_hI-Fgpwl-"
      },
      "source": [
        "print(vars(train_data.examples[0])['ptbtags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TYUko-Bpwl-"
      },
      "source": [
        "Что мы сделаем дальше:\n",
        "\n",
        "* Мы создадим словарь - отображение токенов в целые числа.\n",
        "\n",
        "* Мы хотим, чтобы в нашем наборе данных были некоторые неизвестные токены, чтобы воссоздать, как эта модель будет использоваться в реальной жизни, поэтому мы устанавливаем `min_freq = 2`, что означает, что в словарь будут добавлены только токены, появляющиеся хотя бы дважды в обучающем наборе, и остальные будут заменены токенами `<unk>`.\n",
        "\n",
        "* Мы также загружаем предобученные векторы GloVe длины 100 для инициализации эмбеддингов.\n",
        "\n",
        "* `unk_init` используется для инициализации эмбеддингов токенов, которых нет в словаре предварительно обученных вложений. По умолчанию эта инициализация устанавливает эти эмбеддинги в нули, однако лучше избежать их инициализации одним и тем же значением, поэтому мы инициализируем их из нормального распределения.\n",
        "\n",
        "* Предобученные векторы загружаем в наш словарь и будем инициализировать нашу модель этими значениями позже."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание\n",
        "\n",
        "По тренировочным данным постройте три словаря, используя `build_vocab`:\n",
        "\n",
        "* Cловарь по текстам `TEXT` с гиперпараметрами:\n",
        "  * min_freq = MIN_FREQ\n",
        "  * vectors = \"glove.6B.100d\"\n",
        "  * unk_init = torch.Tensor.normal_\n",
        "\n",
        "* Словарь по `UD_TAGS`\n",
        "\n",
        "* Словарь по `PTB_TAGS`\n",
        "\n",
        "Сколько уникальных токенов в словаре, построенном по текстам?"
      ],
      "metadata": {
        "id": "R4V40fC1dLEA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGKCnORWpwl_"
      },
      "source": [
        "MIN_FREQ = 2\n",
        "\n",
        "# ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-jeBfsSpwmG"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Какой самый популярный (часто встречающийся) токен в словаре, построенном по текстам?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFHRIvpMpwmH"
      },
      "source": [
        "# ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pj_pOsqpwmJ"
      },
      "source": [
        "Посмотрим на функцию, вычисляющую процентное соотношение тегов в текстах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee-Hm4E-pwmJ"
      },
      "source": [
        "def tag_percentage(tag_counts):\n",
        "\n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "\n",
        "    return tag_counts_percentages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание\n",
        "\n",
        "Пользуясь функцией `tag_percentage`, выведите на экран процентное соотношение каждого UD-тэга.\n",
        "\n",
        "Какой тег встречается в текстах чаще всего (в процентах)?"
      ],
      "metadata": {
        "id": "bWF7fqNEd69_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2sFxAAHpwmJ"
      },
      "source": [
        "# ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOu9Uv6ZpwmL"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Используя `BucketIterator.split`, создайте объекты `train_iterator, valid_iterator, test_iterator` для итерирования по батчам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78DjTNiJpwmL"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = # ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-KCF_thpwmO"
      },
      "source": [
        "## Создаем архитектуру нейронной сети\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-pos-tagging/blob/master/assets/pos-bidirectional-lstm.png?raw=1)\n",
        "\n",
        "Задайте нейронную сеть по аналогии с сетью из вебинара:\n",
        "\n",
        "* Слой Embedding:\n",
        "  * помимо прочего задайте `padding_idx = pad_idx`\n",
        "\n",
        "* Затем слой LSTM с гиперпараметрами:\n",
        "  * `n_layers = 1`\n",
        "  * `bidirectional = True`\n",
        "  * задайте `dropout`\n",
        "\n",
        "* Затем DropOut слой\n",
        "\n",
        "* Линейный слой, принимающий на вход `hidden_dim * 2` нейронов (так как двунаправленная сеть) и на выходе `output_dim` нейронов\n",
        "\n",
        "В ответ на задание выберите, как выглядит первая строчка в архитектуре сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Wa3Tp5pwmO"
      },
      "source": [
        "class BiLSTMPOSTagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # ваш код здесь\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #pass text through embedding layer and then through dropout layer\n",
        "        embedded = # ваш код здесь\n",
        "\n",
        "        #pass embeddings into LSTM\n",
        "        outputs, (hidden, cell) = # ваш код здесь\n",
        "\n",
        "        #apply dropout and then linear layer\n",
        "        predictions = # ваш код здесь\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTjQq-Eqpwmi"
      },
      "source": [
        "## Обучение модели\n",
        "\n",
        "## Задание\n",
        "\n",
        "Запустите ячейку ниже. Если класс `BiLSTMPOSTagger` реализован корректно, ячейка отработает без ошибок. Получилось?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crDf8hTHpwmi"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = BiLSTMPOSTagger(INPUT_DIM,\n",
        "                        EMBEDDING_DIM,\n",
        "                        HIDDEN_DIM,\n",
        "                        OUTPUT_DIM,\n",
        "                        N_LAYERS,\n",
        "                        BIDIRECTIONAL,\n",
        "                        DROPOUT,\n",
        "                        PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0xJFAApwmi"
      },
      "source": [
        "Инициализируем веса сети числами из стандартного нормального распределения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEq91x0Epwmj"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQmNFG_wpwmj"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Напишите функцию для вычисления количества весов сети.\n",
        "\n",
        "С помощью этой функции выведите на экран число весов нашей сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfPyt7TTpwmk"
      },
      "source": [
        "def count_parameters(model):\n",
        "    # ваш код здесь\n",
        "\n",
        "# ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTVuLKdFpwmk"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Инициализируйте embedding-слой сети предобученными GloVe-векторами.\n",
        "\n",
        "В ответ напишите число координат в предобученных эмбеддингах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-H-ucDCpwml"
      },
      "source": [
        "# ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем нулями pad-токены"
      ],
      "metadata": {
        "id": "vDD0mql7rR7W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pbjDSgNpwmm"
      },
      "source": [
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO51ESn5pwmn"
      },
      "source": [
        "Зададим оптимизатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpCGPGTkpwmn"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8EQh0BGpwmn"
      },
      "source": [
        "Зададим loss.\n",
        "\n",
        "В случае токена `<pad>` (пустота) лосс мы не считаем, поэтому индексы таких токенов мы пропускаем (игнорируем)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOhdfyscpwmo"
      },
      "source": [
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmiF0b31pwmo"
      },
      "source": [
        "Переносим модель на GPU по возможности"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHLdYmqhpwmp"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIgmzjvEpwmq"
      },
      "source": [
        "Функция ниже вычисляет `accuracy` для каждого батча"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6FMQ9Pppwmq"
      },
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / y[non_pad_elements].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzbRWYkIpwmq"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Допишите цикл обучения модели.\n",
        "\n",
        "Для каждого батча на каждой итерации:\n",
        "- зануляем градиенты\n",
        "- применяем модель к батчу\n",
        "- делаем reshape прогнозов, так как loss нельзя вычислить для тензора размерности 3 (это уже написано)\n",
        "- вычисляем loss и accuracy\n",
        "- вычисляем градиенты и делаем шаг градиентного спуска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QGjrEYppwmr"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        # ваш код здесь\n",
        "\n",
        "        predictions = predictions.view(-1, predictions.shape[-1]) # predictions - прогнозы модели\n",
        "        tags = tags.view(-1) # tags - правильные ответы (метки)\n",
        "\n",
        "        # ваш код здесь\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkdJ4J-Gpwms"
      },
      "source": [
        "Функцию `evaluate` для простоты мы написали."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoxU16Sbpwms"
      },
      "source": [
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.udtags\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUnSxXfmpwmt"
      },
      "source": [
        "Ниже функция, которая замеряет время обучения на каждой эпохе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM2Mfyohpwmt"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlWPogO8pwmv"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Обучим нашу модель. Допишите цикл по подсказкам в коде.\n",
        "\n",
        "Какая accuracy (в процентах) получается на валидации на последней эпохе? Ответ округлите до целого числа."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W08Crfvzpwmw"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = # ваш код здесь - примените функцию для обучения модели\n",
        "    valid_loss, valid_acc = # ваш код здесь - примените функцию для применения и оценки качества модели\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = # замерьте время выполнения эпохи, используя написанную для этого функцию\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "\n",
        "\n",
        "    # для каждой эпохи выведите train loss, train accuracy, val loss, val accuracy, epoch time\n",
        "    # ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMKuvg9apwmw"
      },
      "source": [
        "Посмотрим на качество обученной модели на тесте"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWVYuxHqpwmx"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoRcN30cpwmx"
      },
      "source": [
        "## Инференс\n",
        "\n",
        "Посмотрим, как модель работает на новых данных. Допишите функцию `tag_sentence` для применения обученной модели, по подсказкам ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czlCsTpApwmx"
      },
      "source": [
        "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
        "\n",
        "    # ваш код здесь - переведите модель в режим применения\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        tokens = [token.text for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token for token in sentence]\n",
        "\n",
        "    if text_field.lower:\n",
        "        tokens = [t.lower() for t in tokens]\n",
        "\n",
        "    numericalized_tokens = # ваш код здесь - создайте список, состоящий из переведенных в индексы токенов из словаря text_field.vocab (используйте stoi)\n",
        "\n",
        "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
        "\n",
        "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
        "\n",
        "    token_tensor = # ваш код здесь - приведите numericalized_tokens к типу torch.LongTensor\n",
        "\n",
        "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
        "\n",
        "    predictions = # ваш код здесь - примените модель к token_tenzor\n",
        "\n",
        "    top_predictions = predictions.argmax(-1)\n",
        "\n",
        "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
        "\n",
        "    return tokens, predicted_tags, unks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VG1mjbEpwmy"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Запустите две следующие ячейки. Проверим, что написанная функция работает корректно.\n",
        "\n",
        "В ответе выберите те токены, которые были нераспознаны (их не было в обучающих данных)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX9dYDOhpwmy"
      },
      "source": [
        "example_index = 1\n",
        "\n",
        "sentence = vars(train_data.examples[example_index])['text']\n",
        "actual_tags = vars(train_data.examples[example_index])['udtags']\n",
        "\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJmb8kVTpwmy"
      },
      "source": [
        "tokens, pred_tags, unks = tag_sentence(model,\n",
        "                                       device,\n",
        "                                       sentence,\n",
        "                                       TEXT,\n",
        "                                       UD_TAGS)\n",
        "\n",
        "print(unks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zAXE1KTpwmy"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Проверим качество модели. Запустите ячейку ниже. В ответе укажите число неверно классифицированных токенов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hixzgb6fpwmz"
      },
      "source": [
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "\n",
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2o_BtQspwm2"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Примените модель к любому предложению (на английском языке). Какая доля токенов размечена верно? Ответ напишите в комментариях."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEO3Wy48pwm5"
      },
      "source": [
        "# ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}