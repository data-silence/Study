{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scyE4k8gpwl0"
      },
      "source": [
        "# Домашнее задание: BiLSTM для задачи PoS Tagging\n",
        "\n",
        "В этом ноутбуке мы будем создавать модель машинного обучения, которая генерирует результат для каждого элемента входной последовательности с использованием PyTorch и TorchText. Конкретно, мы будем подавать текст на вход, а модель будет выводить метку - часть речи (PoS) для каждого токена во входном тексте. Этот подход также может применяться для распознавания именованных сущностей (NER), где результатом для каждого токена будет указание на тип сущности, если таковая имеется.\n",
        "\n",
        "В этом блокноте мы реализуем многослойную двунаправленную LSTM (BiLSTM) для предсказания меток частей речи с использованием набора данных Universal Dependencies English Web Treebank (UDPOS)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "id": "5Xf-0XQQW9G8",
        "outputId": "2c7e7272-5bb3-46df-c182-7b9fbd42e3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9osUMmompwl2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5OZxOjBpwl3"
      },
      "source": [
        "Зафиксируем случайности для воспроизводимости результатов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egSkC0DDpwl4"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTuoKelVpwl4"
      },
      "source": [
        "В этом наборе данных есть два разных набора меток: метки универсальных зависимостей (UD) и метки Penn Treebank (PTB). Мы будем обучать модель только на метках UD, но загрузим метки PTB, чтобы показать, как их можно использовать вместо них.\n",
        "\n",
        "* UD_TAGS определяет, как следует обрабатывать метки UD. В нашем словаре TEXT, который мы создадим позже, будут неизвестные токены, то есть токены, которых нет в нашем словаре. Однако у нас не будет неизвестных меток, поскольку мы имеем дело с конечным набором возможных меток. Мы будем обозначать неизвестные токены как <unk>, и затем будем их убирать, установив unk_token = None.\n",
        "\n",
        "* PTB_TAGS выполняет то же самое, что и UD_TAGS, но обрабатывает метки PTB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fidoBBJfpwl5"
      },
      "source": [
        "from torchtext.data import Field\n",
        "\n",
        "TEXT = Field(lower = True)\n",
        "UD_TAGS = Field(unk_token = None)\n",
        "PTB_TAGS = Field(unk_token = None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqya4Ki-pwl6"
      },
      "source": [
        "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AHzDh46pwl7"
      },
      "source": [
        "Загрузим датасет UDPOS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_RLyzzpwl7",
        "outputId": "60cc7290-d98c-4793-e3ce-4cf7d57b2964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading en-ud-v2.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 2.16MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cHlSTlEpwl7"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Посмотрите на количество объектов в датасетах `train_data, valid_data и test_data`. В ответ запишите число объектов в самом маленьком датасете."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "metadata": {
        "id": "WVZYYS5P64io",
        "outputId": "69c4314f-bdad-43d6-9244-0df43bf093df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12543, 2002, 2077)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCznT-c3pwl8",
        "outputId": "86233bea-4c46-4a32-aa31-72f08a4c97aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for el in train_data[:1]:\n",
        "  print(el.text, el.udtags)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.'] ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIY61Z5Cpwl9"
      },
      "source": [
        "Напечатаем пример из датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpadMDOCpwl9",
        "outputId": "0a4b8939-05f7-4b25-a4a8-d4256356c280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.'], 'udtags': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], 'ptbtags': ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39xsVtxpwl9"
      },
      "source": [
        "Можем отдельно посмотреть на текст и на теги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UULauMEBpwl-"
      },
      "source": [
        "print(vars(train_data.examples[0])['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACWgCsPqpwl-"
      },
      "source": [
        "print(vars(train_data.examples[0])['udtags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko_hI-Fgpwl-"
      },
      "source": [
        "print(vars(train_data.examples[0])['ptbtags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TYUko-Bpwl-"
      },
      "source": [
        "Что мы сделаем дальше:\n",
        "\n",
        "* Мы создадим словарь - отображение токенов в целые числа.\n",
        "\n",
        "* Мы хотим, чтобы в нашем наборе данных были некоторые неизвестные токены, чтобы воссоздать, как эта модель будет использоваться в реальной жизни, поэтому мы устанавливаем `min_freq = 2`, что означает, что в словарь будут добавлены только токены, появляющиеся хотя бы дважды в обучающем наборе, и остальные будут заменены токенами `<unk>`.\n",
        "\n",
        "* Мы также загружаем предобученные векторы GloVe длины 100 для инициализации эмбеддингов.\n",
        "\n",
        "* `unk_init` используется для инициализации эмбеддингов токенов, которых нет в словаре предварительно обученных вложений. По умолчанию эта инициализация устанавливает эти эмбеддинги в нули, однако лучше избежать их инициализации одним и тем же значением, поэтому мы инициализируем их из нормального распределения.\n",
        "\n",
        "* Предобученные векторы загружаем в наш словарь и будем инициализировать нашу модель этими значениями позже."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание\n",
        "\n",
        "По тренировочным данным постройте три словаря, используя `build_vocab`:\n",
        "\n",
        "* Cловарь по текстам `TEXT` с гиперпараметрами:\n",
        "  * min_freq = MIN_FREQ\n",
        "  * vectors = \"glove.6B.100d\"\n",
        "  * unk_init = torch.Tensor.normal_\n",
        "\n",
        "* Словарь по `UD_TAGS`\n",
        "\n",
        "* Словарь по `PTB_TAGS`\n",
        "\n",
        "Сколько уникальных токенов в словаре, построенном по текстам?"
      ],
      "metadata": {
        "id": "R4V40fC1dLEA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGKCnORWpwl_",
        "outputId": "45325a27-64da-4f0d-8ae4-267fa73476f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MIN_FREQ = 2\n",
        "\n",
        "# build_vocab -- создать словарь по данному полю в датасете\n",
        "TEXT.build_vocab(\n",
        "    train_data,\n",
        "    min_freq=MIN_FREQ,\n",
        "    vectors=\"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "\n",
        "# В тэгах/лейблах не используем гиперпараметры, потому как там просто метки, эта обработка бессмысленна\n",
        "UD_TAGS.build_vocab(train_data)\n",
        "PTB_TAGS.build_vocab(train_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:28<00:00, 13908.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{len(TEXT.vocab)=}, {len(UD_TAGS.vocab)=}, {len(PTB_TAGS.vocab)=}')"
      ],
      "metadata": {
        "id": "LDMPbeF-AWRJ",
        "outputId": "184bfcee-0b0b-499e-f5b7-e6e2b231302f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(TEXT.vocab)=8866, len(UD_TAGS.vocab)=18, len(PTB_TAGS.vocab)=51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-jeBfsSpwmG"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Какой самый популярный (часто встречающийся) токен в словаре, построенном по текстам?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFHRIvpMpwmH",
        "outputId": "a7369256-ee67-4931-9038-1ea24ba75eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TEXT.vocab.freqs.most_common(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 9076), ('.', 8640), (',', 7021), ('to', 5137), ('and', 5002)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pj_pOsqpwmJ"
      },
      "source": [
        "Посмотрим на функцию, вычисляющую процентное соотношение тегов в текстах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee-Hm4E-pwmJ"
      },
      "source": [
        "def tag_percentage(tag_counts):\n",
        "\n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "\n",
        "    return tag_counts_percentages"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание\n",
        "\n",
        "Пользуясь функцией `tag_percentage`, выведите на экран процентное соотношение каждого UD-тэга.\n",
        "\n",
        "Какой тег встречается в текстах чаще всего (в процентах)?"
      ],
      "metadata": {
        "id": "bWF7fqNEd69_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2sFxAAHpwmJ",
        "outputId": "2964bdd7-120a-4a6c-812b-3ae9fbe0c5d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "UD_TAGS.vocab.freqs.most_common()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NOUN', 34781),\n",
              " ('PUNCT', 23679),\n",
              " ('VERB', 23081),\n",
              " ('PRON', 18577),\n",
              " ('ADP', 17638),\n",
              " ('DET', 16285),\n",
              " ('PROPN', 12946),\n",
              " ('ADJ', 12477),\n",
              " ('AUX', 12343),\n",
              " ('ADV', 10548),\n",
              " ('CCONJ', 6707),\n",
              " ('PART', 5567),\n",
              " ('NUM', 3999),\n",
              " ('SCONJ', 3843),\n",
              " ('X', 847),\n",
              " ('INTJ', 688),\n",
              " ('SYM', 599)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tag\\t\\tCount\\t\\tPercentage\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(UD_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
      ],
      "metadata": {
        "id": "IFIFJaJICnfY",
        "outputId": "9391daf7-7002-46d8-cfe3-847de946cce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag\t\tCount\t\tPercentage\n",
            "\n",
            "NOUN\t\t34781\t\t17.0%\n",
            "PUNCT\t\t23679\t\t11.6%\n",
            "VERB\t\t23081\t\t11.3%\n",
            "PRON\t\t18577\t\t 9.1%\n",
            "ADP\t\t17638\t\t 8.6%\n",
            "DET\t\t16285\t\t 8.0%\n",
            "PROPN\t\t12946\t\t 6.3%\n",
            "ADJ\t\t12477\t\t 6.1%\n",
            "AUX\t\t12343\t\t 6.0%\n",
            "ADV\t\t10548\t\t 5.2%\n",
            "CCONJ\t\t6707\t\t 3.3%\n",
            "PART\t\t5567\t\t 2.7%\n",
            "NUM\t\t3999\t\t 2.0%\n",
            "SCONJ\t\t3843\t\t 1.9%\n",
            "X\t\t847\t\t 0.4%\n",
            "INTJ\t\t688\t\t 0.3%\n",
            "SYM\t\t599\t\t 0.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOu9Uv6ZpwmL"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Используя `BucketIterator.split`, создайте объекты `train_iterator, valid_iterator, test_iterator` для итерирования по батчам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78DjTNiJpwmL"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "        (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_iterator:\n",
        "    print(item.text, item.udtags)\n",
        "    print(item.text.shape, item.udtags.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "SNvBO3cFEqNC",
        "outputId": "bd2d2f6f-6a4b-4366-ed03-a3101aefbdaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 352, 6609,   14,  ...,  381,  132,   70],\n",
            "        [ 545,    1,   29,  ...,  121,   14,  632],\n",
            "        [ 144,    1,   67,  ..., 3042,   11,  500],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    0,    1,    1],\n",
            "        [   1,    1,    1,  ...,   31,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0') tensor([[ 8,  7,  4,  ...,  3, 10,  6],\n",
            "        [ 1,  0,  9,  ...,  5,  4,  1],\n",
            "        [ 9,  0, 10,  ...,  1,  9,  1],\n",
            "        ...,\n",
            "        [ 0,  0,  0,  ...,  1,  0,  0],\n",
            "        [ 0,  0,  0,  ...,  2,  0,  0],\n",
            "        [ 0,  0,  0,  ...,  2,  0,  0]], device='cuda:0')\n",
            "torch.Size([52, 128]) torch.Size([52, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-KCF_thpwmO"
      },
      "source": [
        "## Создаем архитектуру нейронной сети\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-pos-tagging/blob/master/assets/pos-bidirectional-lstm.png?raw=1)\n",
        "\n",
        "Задайте нейронную сеть по аналогии с сетью из вебинара:\n",
        "\n",
        "* Слой Embedding:\n",
        "  * помимо прочего задайте `padding_idx = pad_idx`\n",
        "\n",
        "* Затем слой LSTM с гиперпараметрами:\n",
        "  * `n_layers = 1`\n",
        "  * `bidirectional = True`\n",
        "  * задайте `dropout`\n",
        "\n",
        "* Затем DropOut слой\n",
        "\n",
        "* Линейный слой, принимающий на вход `hidden_dim * 2` нейронов (так как двунаправленная сеть) и на выходе `output_dim` нейронов\n",
        "\n",
        "В ответ на задание выберите, как выглядит первая строчка в архитектуре сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Wa3Tp5pwmO"
      },
      "source": [
        "class BiLSTMPOSTagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim=embedding_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, bidirectional=True, num_layers=1, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        #pass text through embedding layer and then through dropout layer\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        #pass embeddings into LSTM\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        #outputs содержит прямые и обратные скрытые состояния в конечном слое\n",
        "        #hidden и cell - состояния скрытого слоя и ячейки в обратном и прямом направлении на последнем временном шаге\n",
        "\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        #apply dropout and then linear layer\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTjQq-Eqpwmi"
      },
      "source": [
        "## Обучение модели\n",
        "\n",
        "## Задание\n",
        "\n",
        "Запустите ячейку ниже. Если класс `BiLSTMPOSTagger` реализован корректно, ячейка отработает без ошибок. Получилось?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crDf8hTHpwmi",
        "outputId": "d6888119-b761-4d10-8579-d71b46a3dba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = BiLSTMPOSTagger(INPUT_DIM,\n",
        "                        EMBEDDING_DIM,\n",
        "                        HIDDEN_DIM,\n",
        "                        OUTPUT_DIM,\n",
        "                        N_LAYERS,\n",
        "                        BIDIRECTIONAL,\n",
        "                        DROPOUT,\n",
        "                        PAD_IDX)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0xJFAApwmi"
      },
      "source": [
        "Инициализируем веса сети числами из стандартного нормального распределения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEq91x0Epwmj",
        "outputId": "d62eaa83-5aa1-43d9-b56d-6ea243bb1327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTMPOSTagger(\n",
              "  (embedding): Embedding(8866, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 128, dropout=0.25, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters"
      ],
      "metadata": {
        "id": "UDBSxh2KOcAb",
        "outputId": "bf37eb76-f308-422b-bf1a-fd623871a47e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of BiLSTMPOSTagger(\n",
              "  (embedding): Embedding(8866, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for el in model.parameters():\n",
        "  print(el.numel())"
      ],
      "metadata": {
        "id": "i3ZE5dQhOtK7",
        "outputId": "2b895f13-7eba-4e89-a8bf-1b2a9e5dbd88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "886600\n",
            "51200\n",
            "65536\n",
            "512\n",
            "512\n",
            "51200\n",
            "65536\n",
            "512\n",
            "512\n",
            "131072\n",
            "65536\n",
            "512\n",
            "512\n",
            "131072\n",
            "65536\n",
            "512\n",
            "512\n",
            "4608\n",
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQmNFG_wpwmj"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Напишите функцию для вычисления количества весов сети.\n",
        "\n",
        "С помощью этой функции выведите на экран число весов нашей сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfPyt7TTpwmk",
        "outputId": "9e56ccb8-df3f-4f9c-8a94-817cf01f8139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Модель содержит {count_parameters(model):,} обучаемых параметров')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель содержит 1,522,010 обучаемых параметров\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTVuLKdFpwmk"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Инициализируйте embedding-слой сети предобученными GloVe-векторами.\n",
        "\n",
        "В ответ напишите число координат в предобученных эмбеддингах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-H-ucDCpwml",
        "outputId": "613a4eac-c84f-402e-c98d-2e7d0bfa998a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8866, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "metadata": {
        "id": "QnEQ-swhRrOv",
        "outputId": "d6a36707-0a64-4e89-d0ea-147712fa07b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.9261,  2.3049,  0.5502,  ..., -0.3492, -0.5298, -0.1577],\n",
              "        [-0.5972,  0.0471, -0.2406,  ..., -0.9446, -0.1126, -0.2260],\n",
              "        [-0.4809,  2.5629,  0.9530,  ...,  0.5278, -0.4588,  0.7294]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем нулями pad-токены"
      ],
      "metadata": {
        "id": "vDD0mql7rR7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM"
      ],
      "metadata": {
        "id": "NDFHKTRyR4NO",
        "outputId": "6faecd9a-4594-44de-d0f3-8a5cc396a3c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_IDX"
      ],
      "metadata": {
        "id": "8TzHBaDWSJRa",
        "outputId": "aaa4c952-c94a-432f-9433-95f959049716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pbjDSgNpwmm",
        "outputId": "46d75733-efc3-40db-9245-ca823465a81f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.9261,  2.3049,  0.5502,  ..., -0.3492, -0.5298, -0.1577],\n",
            "        [-0.5972,  0.0471, -0.2406,  ..., -0.9446, -0.1126, -0.2260],\n",
            "        [-0.4809,  2.5629,  0.9530,  ...,  0.5278, -0.4588,  0.7294]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO51ESn5pwmn"
      },
      "source": [
        "Зададим оптимизатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpCGPGTkpwmn"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8EQh0BGpwmn"
      },
      "source": [
        "Зададим loss.\n",
        "\n",
        "В случае токена `<pad>` (пустота) лосс мы не считаем, поэтому индексы таких токенов мы пропускаем (игнорируем)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOhdfyscpwmo"
      },
      "source": [
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_PAD_IDX"
      ],
      "metadata": {
        "id": "wPixi6nzSXYw",
        "outputId": "0e5d1c42-bcd4-42d9-d79a-f3a9c74fd4ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmiF0b31pwmo"
      },
      "source": [
        "Переносим модель на GPU по возможности"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHLdYmqhpwmp"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIgmzjvEpwmq"
      },
      "source": [
        "Функция ниже вычисляет `accuracy` для каждого батча"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6FMQ9Pppwmq"
      },
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / y[non_pad_elements].shape[0]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzbRWYkIpwmq"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Допишите цикл обучения модели.\n",
        "\n",
        "Для каждого батча на каждой итерации:\n",
        "- зануляем градиенты\n",
        "- применяем модель к батчу\n",
        "- делаем reshape прогнозов, так как loss нельзя вычислить для тензора размерности 3 (это уже написано)\n",
        "- вычисляем loss и accuracy\n",
        "- вычисляем градиенты и делаем шаг градиентного спуска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QGjrEYppwmr"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "      text = batch.text\n",
        "      tags = batch.udtags\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #text = [sent len, batch size]\n",
        "\n",
        "      predictions = model(text)\n",
        "      #predictions = [sent len, batch size, output dim]\n",
        "      #tags = [sent len, batch size]\n",
        "\n",
        "      predictions = predictions.view(-1, predictions.shape[-1]) # predictions - прогнозы модели\n",
        "      tags = tags.view(-1) # tags - правильные ответы (метки)\n",
        "\n",
        "      loss = criterion(predictions, tags)\n",
        "      acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkdJ4J-Gpwms"
      },
      "source": [
        "Функцию `evaluate` для простоты мы написали."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoxU16Sbpwms"
      },
      "source": [
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.udtags\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUnSxXfmpwmt"
      },
      "source": [
        "Ниже функция, которая замеряет время обучения на каждой эпохе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM2Mfyohpwmt"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlWPogO8pwmv"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Обучим нашу модель. Допишите цикл по подсказкам в коде.\n",
        "\n",
        "Какая accuracy (в процентах) получается на валидации на последней эпохе? Ответ округлите до целого числа."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W08Crfvzpwmw",
        "outputId": "855c22c1-e99d-4cc7-984f-bd5bc8c6a637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX) # примените функцию для обучения модели\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX) # ваш код здесь - примените функцию для применения и оценки качества модели\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time) # замерьте время выполнения эпохи, используя написанную для этого функцию\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.525 | Train Acc: 55.83%\n",
            "\t Val. Loss: 0.834 |  Val. Acc: 76.60%\n",
            "Epoch: 02 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.508 | Train Acc: 84.93%\n",
            "\t Val. Loss: 0.559 |  Val. Acc: 82.71%\n",
            "Epoch: 03 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.356 | Train Acc: 89.13%\n",
            "\t Val. Loss: 0.480 |  Val. Acc: 84.62%\n",
            "Epoch: 04 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.293 | Train Acc: 90.88%\n",
            "\t Val. Loss: 0.448 |  Val. Acc: 85.49%\n",
            "Epoch: 05 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.258 | Train Acc: 91.89%\n",
            "\t Val. Loss: 0.422 |  Val. Acc: 86.19%\n",
            "Epoch: 06 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.233 | Train Acc: 92.65%\n",
            "\t Val. Loss: 0.410 |  Val. Acc: 86.51%\n",
            "Epoch: 07 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.214 | Train Acc: 93.16%\n",
            "\t Val. Loss: 0.395 |  Val. Acc: 87.26%\n",
            "Epoch: 08 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.199 | Train Acc: 93.69%\n",
            "\t Val. Loss: 0.389 |  Val. Acc: 87.01%\n",
            "Epoch: 09 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.185 | Train Acc: 94.06%\n",
            "\t Val. Loss: 0.378 |  Val. Acc: 88.91%\n",
            "Epoch: 10 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.175 | Train Acc: 94.32%\n",
            "\t Val. Loss: 0.379 |  Val. Acc: 88.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMKuvg9apwmw"
      },
      "source": [
        "Посмотрим на качество обученной модели на тесте"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWVYuxHqpwmx",
        "outputId": "b6e95654-2650-4c9d-94d2-4a875afc0d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.395 |  Test Acc: 88.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoRcN30cpwmx"
      },
      "source": [
        "## Инференс\n",
        "\n",
        "Посмотрим, как модель работает на новых данных. Допишите функцию `tag_sentence` для применения обученной модели, по подсказкам ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czlCsTpApwmx"
      },
      "source": [
        "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
        "\n",
        "    model.eval() # ваш код здесь - переведите модель в режим применения\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        tokens = [token.text for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token for token in sentence]\n",
        "\n",
        "    if text_field.lower:\n",
        "        tokens = [t.lower() for t in tokens]\n",
        "\n",
        "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens] # ваш код здесь - создайте список, состоящий из переведенных в индексы токенов из словаря text_field.vocab (используйте stoi)\n",
        "\n",
        "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
        "\n",
        "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
        "\n",
        "    token_tensor = torch.LongTensor(numericalized_tokens) # ваш код здесь - приведите numericalized_tokens к типу torch.LongTensor\n",
        "\n",
        "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
        "\n",
        "    predictions = model(token_tensor) # ваш код здесь - примените модель к token_tenzor\n",
        "\n",
        "    top_predictions = predictions.argmax(-1)\n",
        "\n",
        "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
        "\n",
        "    return tokens, predicted_tags, unks"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VG1mjbEpwmy"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Запустите две следующие ячейки. Проверим, что написанная функция работает корректно.\n",
        "\n",
        "В ответе выберите те токены, которые были нераспознаны (их не было в обучающих данных)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX9dYDOhpwmy",
        "outputId": "7f92db53-d33c-4134-ab9d-d1efbc5b6cd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "example_index = 1\n",
        "\n",
        "sentence = vars(train_data.examples[example_index])['text']\n",
        "actual_tags = vars(train_data.examples[example_index])['udtags']\n",
        "\n",
        "print(sentence)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'this', 'killing', 'of', 'a', 'respected', 'cleric', 'will', 'be', 'causing', 'us', 'trouble', 'for', 'years', 'to', 'come', '.', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJmb8kVTpwmy",
        "outputId": "d0b0e162-612d-4010-8dd9-dc08ad85073b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens, pred_tags, unks = tag_sentence(model,\n",
        "                                       device,\n",
        "                                       sentence,\n",
        "                                       TEXT,\n",
        "                                       UD_TAGS)\n",
        "\n",
        "print(unks)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['respected', 'cleric']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zAXE1KTpwmy"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Проверим качество модели. Запустите ячейку ниже. В ответе укажите число неверно классифицированных токенов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hixzgb6fpwmz",
        "outputId": "0972ab7c-8916-47e7-b6a0-5c1398a474d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "\n",
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "PUNCT\t\tPUNCT\t\t✔\t\t[\n",
            "DET\t\tDET\t\t✔\t\tthis\n",
            "VERB\t\tNOUN\t\t✘\t\tkilling\n",
            "ADP\t\tADP\t\t✔\t\tof\n",
            "DET\t\tDET\t\t✔\t\ta\n",
            "NOUN\t\tADJ\t\t✘\t\trespected\n",
            "NOUN\t\tNOUN\t\t✔\t\tcleric\n",
            "AUX\t\tAUX\t\t✔\t\twill\n",
            "AUX\t\tAUX\t\t✔\t\tbe\n",
            "VERB\t\tVERB\t\t✔\t\tcausing\n",
            "PRON\t\tPRON\t\t✔\t\tus\n",
            "NOUN\t\tNOUN\t\t✔\t\ttrouble\n",
            "ADP\t\tADP\t\t✔\t\tfor\n",
            "NOUN\t\tNOUN\t\t✔\t\tyears\n",
            "PART\t\tPART\t\t✔\t\tto\n",
            "VERB\t\tVERB\t\t✔\t\tcome\n",
            "PUNCT\t\tPUNCT\t\t✔\t\t.\n",
            "PUNCT\t\tPUNCT\t\t✔\t\t]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2o_BtQspwm2"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Примените модель к любому предложению (на английском языке). Какая доля токенов размечена верно? Ответ напишите в комментариях."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "\n",
        "for token, tag in zip(tokens, tags):\n",
        "    print(f\"{tag}\\t\\t{token}\")"
      ],
      "metadata": {
        "id": "qSX6EuXKa7Cd",
        "outputId": "126c30d2-2d22-46cf-ba41-54d103e6e126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred. Tag\tToken\n",
            "\n",
            "PRON\t\ti\n",
            "VERB\t\tlove\n",
            "DET\t\tthis\n",
            "NOUN\t\tgame\n",
            "PUNCT\t\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEO3Wy48pwm5",
        "outputId": "a90a1d95-1f5b-4e5e-9cbf-fbbba13fb1ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentence = 'I love this game.'\n",
        "\n",
        "tokens, tags, unks = tag_sentence(model,\n",
        "                                  device,\n",
        "                                  sentence,\n",
        "                                  TEXT,\n",
        "                                  UD_TAGS)\n",
        "\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "metadata": {
        "id": "4eUKrolkbNj3",
        "outputId": "8298a118-5691-4a8e-ebf8-04d3f71d1a04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PUNCT\t\tPUNCT\t\t✔\t\ti\n",
            "DET\t\tDET\t\t✔\t\tlove\n",
            "VERB\t\tNOUN\t\t✘\t\tthis\n",
            "ADP\t\tADP\t\t✔\t\tgame\n",
            "DET\t\tDET\t\t✔\t\t.\n"
          ]
        }
      ]
    }
  ]
}